# RAG with knowledge graph

Retriever-Augmented Generation (RAG) models combine the powers of pre-trained language models with an external knowledge retrieval mechanism to enhance the model's ability to generate more accurate, informative, and contextually relevant responses.

Knowledge graphs (KG) represent information in a structured format, with entities as nodes and relationships between these entities as edges. This structure allows RAG models to understand and leverage complex relationships and hierarchies in the data, leading to more nuanced and accurate generation of content.

Benefits:
- The structured nature of knowledge graphs enables RAG models to retrieve information that is not only relevant but also highly precise. By understanding the specific context of a query, the model can navigate the graph to find the exact piece of information needed, improving the quality of the generated responses.
- KG are curated and often verified sources of information, which can significantly enhance the factuality of the responses generated by RAG models. This is particularly important for applications requiring high levels of accuracy, such as educational tools, medical advice, and news generation.
- Dynamic updating: Knowledge graphs can be continuously updated with new information, allowing RAG models to stay current with the latest facts and figures. 
- Enhanced Disambiguation: The ability to understand and distinguish between entities that share similar names or attributes (disambiguation) is greatly enhanced by using knowledge graphs. This is because the graph not only contains information about the entities themselves but also about their relationships with other entities, providing additional context that can be used to resolve ambiguities.
- Multimodal Integration: Knowledge graphs are not limited to textual information; they can also incorporate or link to other data types, such as images, videos, and audio files. This capability allows RAG models to leverage multimodal data for generating responses, opening up new possibilities for applications in areas like multimedia content creation and interactive entertainment.

## Scope of the Code

The Jyupyter Notebook shows some simple examples which depicts on code level how to to build a knowledge graph structure from text documents and interact with them in a chat like manner.

The code example came from deeplearning.ai short course "Knowledge Graphs for RAG". This includes a preprocessed JSON file extracted from 10-k finance reporting format (see SEC's [EDGAR database](https://www.sec.gov/edgar/search/)). 

Preprocessing was done with following steps:

- download 10-k documents in XML
- cleaning up the files using regex
- Parsed XML into python data structures using Beautiful Soup
- Extracted CIK (Central Index Key) ID which is a company identifier used by the SEC
- Extracted specific sections of the form (Items 1, 1a, 7, and 7a)

In this repo I did some conceptional review and consolidated everything in a single Jupyter Notebook which you can run easily in your local environment.

## Installation

Technically all data and vector store is persisted in Neo4J Graph DB. All semantical interaction and chaining is done by using the popular open source framework [Langchain](https://www.langchain.com) which allows to build context-aware, reasoning applications.

### Neo4J prerequisites

Take care that `apoc-<current-version>>-core.jar` from labs folder and `neo4j-genai-plugin-<current version>.jar` from products folder is available in the plugin folder of your Neo4J instance.

Note: the community edition is missing the genai plugin.

Take care that these plugins can be executed - e.g. check your neo4j.conf.

Example:
```bash
dbms.security.procedures.unrestricted=apoc.*,genai.*
dbms.security.procedures.allowlist=apoc.*,genai.*
```

I created a neo4j desktop instance containig the fowllowing databases:
- neo4j - containing the default movie db from neo4j in order to show the basic concepts, how to interact with a neo4J based knowledge Graph
- ten-k - you should create an empty DB and knowledge graph construction will be explained and performed in the jupyter notebook
- ten-k-full - the full graph as provided by the course (sse dump file), last chapter of the notebook uses this

All source data is publicy available.

### Python packages
All required packages are listed in requirments.txt.

`pip install -r requirements.txt` or use your preferred package manager.

### OPENAI

Embeddings and LLM from Open AI is used. So you need an OPENAI AP key to run the examples.

